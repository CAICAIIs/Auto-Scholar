# [Proposal 3] AI Runtime Layer - Revised Design (Application-First Approach)

> **Author**: Sisyphus (AI Analysis)
> **Status**: Phase 1 Implemented
> **Based on**: Issue #2 discussion with source code analysis of Dify, OpenHands, and Haystack

---

## TL;DR

ä¸º Auto-Scholar è®¾è®¡ä¸€ä¸ª**åº”ç”¨çº§çš„ AI Runtime å±‚**ï¼Œå‚è€ƒ OpenHands æ¶æ„è€Œé Dify å¹³å°çº§æ¶æ„ï¼š

- **Phase 1ï¼ˆæ ¸å¿ƒï¼‰**ï¼šTask-aware è·¯ç”± + Fallback + æ¨¡å‹èƒ½åŠ›æ£€æµ‹ âœ… **å·²å®ç°**
- **Phase 2ï¼ˆæ‰©å±•ï¼‰**ï¼šå¤–éƒ¨é…ç½® YAML + æµå¼è¾“å‡º + æˆæœ¬è¿½è¸ª
- **Phase 3ï¼ˆé«˜çº§ï¼‰**ï¼šEmbedding Provider + å¤šæ¨¡æ€æ”¯æŒ + æ™ºèƒ½ Router æ¨¡å¼

**æ ¸å¿ƒåŸåˆ™**ï¼š
1. åŸºäºç°æœ‰ `llm_client.py` å¢é‡æ‰©å±•ï¼Œé¿å…è¿‡åº¦è®¾è®¡
2. å‚è€ƒ OpenHands åº”ç”¨çº§æ¶æ„ï¼ˆ~120KBï¼Œ12 æ–‡ä»¶ï¼‰ï¼Œè€Œé Dify å¹³å°çº§æ¶æ„ï¼ˆ50+ providersï¼‰
3. æ¸è¿›å¼å‘å±•ï¼Œæ ¹æ®å®é™…éœ€æ±‚æŒ‰éœ€æ·»åŠ æŠ½è±¡
4. ä¸ LangGraph èŠ‚ç‚¹æ¨¡å¼æ— ç¼é›†æˆ

---

## ä¸€ã€ä¸ºä»€ä¹ˆéœ€è¦ AI Runtimeï¼ˆä¿®æ­£ï¼‰

### 1.1 å½“å‰é¡¹ç›®çŠ¶æ€

Auto-Scholar æ˜¯ä¸€ä¸ªåŸºäº LangGraph çš„å­¦æœ¯æ–‡çŒ®ç»¼è¿°ç”Ÿæˆå™¨ï¼š

```
planner_agent â†’ retriever_agent â†’ extractor_agent â†’ writer_agent â†’ critic_agent
```

**å·²æœ‰åŸºç¡€è®¾æ–½**ï¼š

| åŠŸèƒ½ | çŠ¶æ€ | ä½ç½® |
|------|------|------|
| ModelProvider æšä¸¾ | âœ… | schemas.py |
| ModelConfig schema | âœ… | schemas.py |
| resolve_model() | âœ… | llm_client.py |
| /api/models ç«¯ç‚¹ | âœ… | main.py |
| Cost tracking | âœ… | evaluation/cost_tracker.py |
| SSE Streaming | âœ… | event_queue.py |

### 1.2 å½“å‰é—®é¢˜

| é—®é¢˜ | å½±å“ | ä¼˜å…ˆçº§ |
|------|------|--------|
| æ‰€æœ‰ä»»åŠ¡ç”¨åŒä¸€æ¨¡å‹ | æˆæœ¬é«˜ | ğŸ”´ é«˜ |
| æ—  Task-aware è·¯ç”± | æ— æ³•æŒ‰ä»»åŠ¡ç‰¹æ€§é€‰æ‹©æœ€ä¼˜æ¨¡å‹ | ğŸ”´ é«˜ |
| æ—  Fallback æœºåˆ¶ | å•ç‚¹æ•…éšœé£é™© | ğŸŸ¡ ä¸­ |
| æ— æ¨¡å‹èƒ½åŠ›æ£€æµ‹ | ç¼ºå°‘æ™ºèƒ½å†³ç­–ä¾æ® | ğŸŸ¡ ä¸­ |
| é…ç½®åˆ†æ•£åœ¨ç¯å¢ƒå˜é‡ | ä¸æ˜“ç®¡ç†å¤æ‚åœºæ™¯ | ğŸŸ¢ ä½ |
| ç¼ºå°‘æµå¼è¾“å‡ºæ¥å£ | æ— æ³•å®æ—¶æ˜¾ç¤ºç”Ÿæˆå†…å®¹ | ğŸŸ¡ ä¸­ |


#### 2.2 æˆæœ¬è¿½è¸ªå¢å¼º
æ‰©å±• `backend/evaluation/cost_tracker.py`ï¼ŒæŒ‰ TaskType ç»Ÿè®¡æˆæœ¬ï¼š
```python
# æ–°å¢å‡½æ•°
def record_llm_usage_by_task(
    prompt_tokens: int,
    completion_tokens: int,
    model: str,
    task_type: TaskType | None = None,
):
    # ... ç°æœ‰å®ç° ...
```
SSE æ–°å¢äº‹ä»¶ç±»å‹ï¼š
```python
{event: "cost_update", task_type: "extraction", cost: 0.045}
```

#### 2.3 Provider å±‚ï¼ˆå¯é€‰ï¼Œæ¨¡å‹æ•°é‡ >5 æ—¶ï¼‰
å½“æ”¯æŒçš„ provider è¶…è¿‡ 3-4 ä¸ªæ—¶ï¼Œè€ƒè™‘å¼•å…¥ Provider å±‚ï¼š
```
backend/llm/providers/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py            # BaseProvider æŠ½è±¡ç±»
â”œâ”€â”€ openai.py         # OpenAI å®ç°
â”œâ”€â”€ anthropic.py      # Anthropic å®ç°
â””â”€â”€ deepseek.py       # DeepSeek å®ç°
```
**ä½•æ—¶éœ€è¦**ï¼šå½“å‘ç°æ¯ä¸ª provider çš„ç‰¹æ®Šé€»è¾‘è¶…è¿‡ 100 è¡Œæ—¶ã€‚

#### 2.4 å‰ç«¯é€‚é…
æ‰©å±• ModelSelector æ”¯æŒæ˜¾ç¤º fallback æ¨¡å‹åˆ—è¡¨å’Œæˆæœ¬ç»Ÿè®¡ï¼š
```typescript
// ModelSelector ç»„ä»¶æ–°å¢å­—æ®µ
interface ModelConfigWithRouting extends ModelConfig {
  isFallback?: boolean;
  taskType?: string;
}
```

### Phase 3: é«˜çº§å±‚ï¼ˆæ˜ç¡®éœ€æ±‚åå†åšï¼‰

#### 3.1 Embedding Provider
å½“ç¡®å®šè¦åš RAGï¼ˆåŸºäºç”¨æˆ·è®ºæ–‡åº“çš„é—®ç­”ï¼‰æ—¶å®ç°ï¼š
```python
# backend/llm/providers/embedding.py
class EmbeddingProvider(BaseProvider):
    async def embed(self, texts: list[str]) -> list[list[float]]:
        """ç”Ÿæˆæ–‡æœ¬å‘é‡"""
```
é›†æˆåˆ° LLM è°ƒç”¨ä¸­ï¼Œæ”¯æŒ hybrid retrievalï¼ˆå‘é‡æ£€ç´¢ + å…³é”®è¯æ£€ç´¢ï¼‰ã€‚

#### 3.2 å¤šæ¨¡æ€æ”¯æŒ
æ”¯æŒåˆ†æè®ºæ–‡ä¸­çš„å›¾è¡¨ã€å…¬å¼ã€è¡¨æ ¼ï¼š
```python
# æ¨¡å‹èƒ½åŠ›æ‰©å±•
class ModelCapability(StrEnum):
    # ... ç°æœ‰èƒ½åŠ› ...
    OCR = "ocr"              # å›¾è¡¨ OCR
    TABLE_EXTRACTION = "table_extraction"  # è¡¨æ ¼æå–
```

#### 3.3 æ™ºèƒ½ Router æ¨¡å¼
å‚è€ƒ OpenHands çš„ `RouterLLM` åŸºç±»ï¼Œæ ¹æ®è¾“å…¥å†…å®¹åŠ¨æ€é€‰æ‹©æ¨¡å‹ï¼š
```python
# backend/llm/router/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py
â””â”€â”€ content_aware.py   # æ ¹æ®è¾“å…¥å†…å®¹é€‰æ¨¡å‹
```

#### 3.4 Prompt ç®¡ç†ç³»ç»Ÿï¼ˆå¯é€‰ï¼‰
å¦‚æœéœ€è¦æ”¯æŒç”¨æˆ·è‡ªå®šä¹‰ promptsï¼š
```
backend/prompts/
â”œâ”€â”€ user/
â”‚   â”œâ”€â”€ planning.yaml
â”‚   â”œâ”€â”€ extraction.yaml
â”‚   â”œâ”€â”€ writing.yaml
â”‚   â””â”€â”€ qa.yaml
â””â”€â”€ __init__.py  # åŠ è½½è¦†ç›–ç³»ç»Ÿ prompts
```

---

## äº”ã€ä¸åŸ Proposal çš„å¯¹æ¯”

| è®¾è®¡å…ƒç´  | åŸ Proposal | ä¿®è®¢ç‰ˆ | åŸå›  |
|---------|-----------|--------|------|
| ç›®å½•ç»“æ„ | `backend/ai/` 20+ æ–‡ä»¶ | `backend/llm/` 4-8 æ–‡ä»¶ | åŸç‰ˆæ˜¯å¹³å°çº§è®¾è®¡ï¼Œä¿®è®¢ç‰ˆæ˜¯åº”ç”¨çº§è®¾è®¡ |
| Gateway ç±» | å•ä¾‹ `LLMGateway` | å‡½æ•°å¼ API (`structured_completion`) | åŸç‰ˆå¢åŠ äº†å¤æ‚åº¦ï¼Œä¿®è®¢ç‰ˆä¿æŒç®€å• |
| é…ç½®æ–¹å¼ | YAML + å¤šè·¯å¾„æœç´¢ + ç¯å¢ƒå˜é‡æ›¿æ¢ | ç®€å• YAML æˆ–ç¯å¢ƒå˜é‡ | åŸç‰ˆè¿‡åº¦å¤æ‚ï¼Œä¿®è®¢ç‰ˆæŒ‰éœ€æ·»åŠ  |
| Tool Registry | å®Œæ•´ Tool ç³»ç»Ÿ | ä¸åšï¼ˆèŠ‚ç‚¹ä¸æ˜¯ ReAct agentï¼‰ | Auto-Scholar å½“å‰ä¸éœ€è¦ |
| ä¸­é—´ä»¶ç³»ç»Ÿ | Pre/Post/Hook ä¸­é—´ä»¶ | ä¸åšï¼ˆç”¨è£…é¥°å™¨å°±å¤Ÿäº†ï¼‰ | åŸç‰ˆè¿‡åº¦è®¾è®¡ |
| Embedding | Phase 1 å°±åš | Phase 3ï¼ˆæ˜ç¡®éœ€æ±‚åï¼‰ | åŸç‰ˆè¿‡æ—©æ·»åŠ  |
| Prompt Registry | Phase 1 å°±åš | Phase 3ï¼ˆå¯é€‰ï¼‰ | åŸç‰ˆè¿‡æ—©æ·»åŠ  |
| ç¼“å­˜å±‚ | Phase 1 å†…å­˜ç¼“å­˜ | ä¸åšï¼ˆç¼“å­˜å‘½ä¸­ç‡æä½ï¼‰ | åŸç‰ˆè€ƒè™‘ä¸å‘¨ |
| å‚è€ƒå¯¹è±¡ | Difyï¼ˆå¹³å°çº§ï¼‰ | OpenHandsï¼ˆåº”ç”¨çº§ï¼‰ | ä¿®æ­£åçš„å‚è€ƒæ›´åŒ¹é… Auto-Scholar å®šä½ |

---

## å…­ã€æ€»ç»“

æœ¬ Proposal åŸºäºå¯¹ Difyã€OpenHandsã€Haystack çš„æºç åˆ†æï¼Œæå‡ºäº†ä¸€ä¸ª**åº”ç”¨çº§çš„ã€æ¸è¿›å¼çš„ AI Runtime å±‚è®¾è®¡æ–¹æ¡ˆ**ï¼š

### æ ¸å¿ƒæ”¹è¿›
1. **å‚è€ƒå¯¹è±¡æ­£ç¡®**ï¼šå‚è€ƒ OpenHandsï¼ˆåº”ç”¨çº§ï¼Œ~120KBï¼‰è€Œé Difyï¼ˆå¹³å°çº§ï¼Œ50+ providersï¼‰
2. **è®¾è®¡åŸåˆ™åŠ¡å®**ï¼šåœ¨ç°æœ‰ `llm_client.py` ä¸Šå¢é‡æ‰©å±•ï¼Œä¸æ¨å€’é‡æ¥
3. **æŠ½è±¡æ·±åº¦é€‚åº¦**ï¼š`backend/llm/` 4-8 ä¸ªæ–‡ä»¶ï¼Œæä¾›ç±»å‹ã€è·¯ç”±ã€èƒ½åŠ›æ£€æµ‹

### Phase åˆ’åˆ†
- **Phase 1ï¼ˆæ ¸å¿ƒï¼Œ~3-5 å¤©ï¼‰**ï¼šTask-aware è·¯ç”± + Fallback + æ¨¡å‹èƒ½åŠ›æ£€æµ‹ âœ… **å·²å®ç°**
- **Phase 2ï¼ˆæ‰©å±•ï¼Œ~1 å‘¨ï¼‰**ï¼šå¤–éƒ¨é…ç½® YAML + æµå¼è¾“å‡º + æˆæœ¬è¿½è¸ª
- **Phase 3ï¼ˆé«˜çº§ï¼ŒæŒ‰éœ€ï¼‰**ï¼šEmbedding Provider + å¤šæ¨¡æ€æ”¯æŒ + æ™ºèƒ½ Router æ¨¡å¼

### Phase 1 å®ç°è¯¦æƒ…

**æ–°å¢æ–‡ä»¶**ï¼ˆ`backend/llm/` ç›®å½•ï¼Œ3 ä¸ªæ–‡ä»¶ï¼‰ï¼š

| æ–‡ä»¶ | èŒè´£ |
|------|------|
| `backend/llm/__init__.py` | åŒ…å¯¼å‡º |
| `backend/llm/task_types.py` | `TaskType` æšä¸¾ï¼ˆ5 ç§ä»»åŠ¡ç±»å‹ï¼‰+ `TaskRequirement` æ•°æ®ç±»ï¼ˆç¡¬çº¦æŸ + è½¯åå¥½ï¼‰ |
| `backend/llm/router.py` | `select_model()` ä¸¤é˜¶æ®µè·¯ç”±ï¼ˆç¡¬è¿‡æ»¤ + è½¯è¯„åˆ†ï¼‰+ `get_fallback_chain()` æœ‰åºå€™é€‰é“¾ |

**ä¿®æ”¹æ–‡ä»¶**ï¼š

| æ–‡ä»¶ | å˜æ›´ |
|------|------|
| `backend/schemas.py` | `ModelConfig` æ–°å¢ 6 ä¸ªèƒ½åŠ›å­—æ®µï¼š`max_context_tokens`ã€`supports_long_context`ã€`cost_tier`ã€`reasoning_score`ã€`creativity_score`ã€`latency_score` |
| `backend/utils/llm_client.py` | `_infer_capabilities()` æŒ‰ provider/model æ¨æ–­èƒ½åŠ›ï¼›`structured_completion()` æ–°å¢ `task_type` å‚æ•° |
| `backend/nodes.py` | æ‰€æœ‰ `structured_completion()` è°ƒç”¨ä¼ å…¥å¯¹åº” `task_type` |
| `backend/utils/claim_verifier.py` | æ‰€æœ‰ `structured_completion()` è°ƒç”¨ä¼ å…¥ `task_type="qa"` |

**è®¾è®¡å†³ç­–**ï¼š
1. ä¸å¼•å…¥ LiteLLMï¼šåªéœ€ 2-3 ä¸ª providerï¼Œç›´æ¥ç”¨ `AsyncOpenAI` + ä¸åŒ `base_url` è¦†ç›–
2. è·¯ç”±ä¸¤é˜¶æ®µï¼šç¡¬çº¦æŸè¿‡æ»¤ï¼ˆstructured_outputã€long_contextã€cost_tierï¼‰â†’ è½¯åå¥½è¯„åˆ†ï¼ˆreasoningã€creativityã€latencyã€cost bonusï¼‰
3. å®Œå…¨å‘åå…¼å®¹ï¼šä¸ä¼  `task_type` æ—¶èµ°åŸæœ‰é»˜è®¤è·¯å¾„
4. èƒ½åŠ›æ¨æ–­ï¼šæŒ‰ provider + model name è‡ªåŠ¨æ¨æ–­ï¼Œæ— éœ€æ‰‹åŠ¨é…ç½®

**æµ‹è¯•è¦†ç›–**ï¼š43 ä¸ªæ–°æµ‹è¯•ï¼ˆtask_types 10 + capabilities 11 + router 22ï¼‰ï¼Œå…¨éƒ¨é€šè¿‡

### é¢„æœŸæ”¶ç›Š
- **æˆæœ¬é™ä½**ï¼šplanner/extractor/critic ç”¨ mini æ¨¡å‹ï¼Œé¢„è®¡èŠ‚çœ 40-60% æˆæœ¬
- **å¯é æ€§æå‡**ï¼šFallback æœºåˆ¶é¿å…å•ç‚¹æ•…éšœ
- **å¯æ‰©å±•æ€§**ï¼šæ¸è¿›å¼å‘å±•ï¼ŒæŒ‰éœ€æ·»åŠ åŠŸèƒ½
- **ä¸ LangGraph åä½œ**ï¼šä¿æŒå‡½æ•°å¼ APIï¼ŒèŠ‚ç‚¹è°ƒç”¨æ–¹å¼ä¸å˜

---

**æ–‡ä»¶åˆ›å»ºæ—¶é—´**ï¼š2026-02-25  
**Phase 1 å®ç°æ—¶é—´**ï¼š2026-02-25  
**çŠ¶æ€**ï¼šPhase 1 å·²å®ç°ï¼ŒPhase 2-3 å¾…è¯„å®¡

